{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X=pd.read_csv('entradas_breast.csv')\n",
    "Y=pd.read_csv('saidas_breast.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>1.184</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.001</td>\n",
       "      <td>1.471</td>\n",
       "      <td>2.419</td>\n",
       "      <td>7.871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1.622</td>\n",
       "      <td>6.656</td>\n",
       "      <td>7.119</td>\n",
       "      <td>2.654</td>\n",
       "      <td>4.601</td>\n",
       "      <td>1.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>8.474</td>\n",
       "      <td>7.864</td>\n",
       "      <td>869.000</td>\n",
       "      <td>7.017</td>\n",
       "      <td>1.812</td>\n",
       "      <td>5.667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.866</td>\n",
       "      <td>2.416</td>\n",
       "      <td>186.000</td>\n",
       "      <td>275.000</td>\n",
       "      <td>8.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>1.096</td>\n",
       "      <td>1.599</td>\n",
       "      <td>1.974</td>\n",
       "      <td>1.279</td>\n",
       "      <td>2.069</td>\n",
       "      <td>5.999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>1.444</td>\n",
       "      <td>4.245</td>\n",
       "      <td>4.504</td>\n",
       "      <td>243.000</td>\n",
       "      <td>3.613</td>\n",
       "      <td>8.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>1.425</td>\n",
       "      <td>2.839</td>\n",
       "      <td>2.414</td>\n",
       "      <td>1.052</td>\n",
       "      <td>2.597</td>\n",
       "      <td>9.744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>2.098</td>\n",
       "      <td>8.663</td>\n",
       "      <td>6.869</td>\n",
       "      <td>2.575</td>\n",
       "      <td>6.638</td>\n",
       "      <td>173.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>1.003</td>\n",
       "      <td>1.328</td>\n",
       "      <td>198.000</td>\n",
       "      <td>1.043</td>\n",
       "      <td>1.809</td>\n",
       "      <td>5.883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>1.374</td>\n",
       "      <td>205.000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>1.625</td>\n",
       "      <td>2.364</td>\n",
       "      <td>7.678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0            1.184   \n",
       "1        20.57         17.77          132.90     1326.0            8.474   \n",
       "2        19.69         21.25          130.00     1203.0            1.096   \n",
       "3        11.42         20.38           77.58      386.1            1.425   \n",
       "4        20.29         14.34          135.10     1297.0            1.003   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave_points_mean  symmetry_mean  \\\n",
       "0             2.776           3.001                1.471          2.419   \n",
       "1             7.864         869.000                7.017          1.812   \n",
       "2             1.599           1.974                1.279          2.069   \n",
       "3             2.839           2.414                1.052          2.597   \n",
       "4             1.328         198.000                1.043          1.809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                   7.871  ...         25.38          17.33           184.60   \n",
       "1                   5.667  ...         24.99          23.41           158.80   \n",
       "2                   5.999  ...         23.57          25.53           152.50   \n",
       "3                   9.744  ...         14.91          26.50            98.87   \n",
       "4                   5.883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0             1.622              6.656            7.119   \n",
       "1      1956.0             1.238              1.866            2.416   \n",
       "2      1709.0             1.444              4.245            4.504   \n",
       "3       567.7             2.098              8.663            6.869   \n",
       "4      1575.0             1.374            205.000            0.400   \n",
       "\n",
       "   concave_points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                 2.654           4.601                    1.189  \n",
       "1               186.000         275.000                    8.902  \n",
       "2               243.000           3.613                    8.758  \n",
       "3                 2.575           6.638                  173.000  \n",
       "4                 1.625           2.364                    7.678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.00000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>706.771388</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>53.418260</td>\n",
       "      <td>28.886329</td>\n",
       "      <td>40.97464</td>\n",
       "      <td>36.058367</td>\n",
       "      <td>18.432831</td>\n",
       "      <td>64.298601</td>\n",
       "      <td>...</td>\n",
       "      <td>315.194921</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>14.057726</td>\n",
       "      <td>35.448107</td>\n",
       "      <td>43.673580</td>\n",
       "      <td>43.891974</td>\n",
       "      <td>32.661968</td>\n",
       "      <td>56.040787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2430.243368</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>192.691499</td>\n",
       "      <td>117.510703</td>\n",
       "      <td>142.13157</td>\n",
       "      <td>123.109612</td>\n",
       "      <td>53.388748</td>\n",
       "      <td>182.029228</td>\n",
       "      <td>...</td>\n",
       "      <td>1655.459336</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>55.312800</td>\n",
       "      <td>122.342078</td>\n",
       "      <td>148.481678</td>\n",
       "      <td>154.494270</td>\n",
       "      <td>89.988802</td>\n",
       "      <td>190.731370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.760000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.210000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>1.137000</td>\n",
       "      <td>1.436000</td>\n",
       "      <td>1.68400</td>\n",
       "      <td>1.967000</td>\n",
       "      <td>1.632000</td>\n",
       "      <td>5.853000</td>\n",
       "      <td>...</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>1.223000</td>\n",
       "      <td>1.843000</td>\n",
       "      <td>1.925000</td>\n",
       "      <td>1.595000</td>\n",
       "      <td>2.527000</td>\n",
       "      <td>6.609000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.850000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>8.293000</td>\n",
       "      <td>4.458000</td>\n",
       "      <td>3.13600</td>\n",
       "      <td>3.515000</td>\n",
       "      <td>1.813000</td>\n",
       "      <td>6.232000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.150000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>1.377000</td>\n",
       "      <td>2.942000</td>\n",
       "      <td>3.486000</td>\n",
       "      <td>2.701000</td>\n",
       "      <td>2.871000</td>\n",
       "      <td>7.628000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.680000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>9.383000</td>\n",
       "      <td>7.542000</td>\n",
       "      <td>6.18100</td>\n",
       "      <td>7.583000</td>\n",
       "      <td>2.035000</td>\n",
       "      <td>6.899000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.850000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>1.562000</td>\n",
       "      <td>5.232000</td>\n",
       "      <td>6.141000</td>\n",
       "      <td>7.763000</td>\n",
       "      <td>3.313000</td>\n",
       "      <td>8.553000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9904.000000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>958.000000</td>\n",
       "      <td>973.00000</td>\n",
       "      <td>974.000000</td>\n",
       "      <td>304.000000</td>\n",
       "      <td>898.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9981.000000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>997.000000</td>\n",
       "      <td>1058.000000</td>\n",
       "      <td>1252.000000</td>\n",
       "      <td>991.000000</td>\n",
       "      <td>544.000000</td>\n",
       "      <td>997.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean    706.771388     19.289649       91.969033   654.889104   \n",
       "std    2430.243368      4.301036       24.298981   351.914129   \n",
       "min       7.760000      9.710000       43.790000   143.500000   \n",
       "25%      12.210000     16.170000       75.170000   420.300000   \n",
       "50%      13.850000     18.840000       86.240000   551.100000   \n",
       "75%      17.680000     21.800000      104.100000   782.700000   \n",
       "max    9904.000000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
       "count       569.000000        569.000000       569.00000           569.000000   \n",
       "mean         53.418260         28.886329        40.97464            36.058367   \n",
       "std         192.691499        117.510703       142.13157           123.109612   \n",
       "min           0.100000          0.060000         0.00000             0.000000   \n",
       "25%           1.137000          1.436000         1.68400             1.967000   \n",
       "50%           8.293000          4.458000         3.13600             3.515000   \n",
       "75%           9.383000          7.542000         6.18100             7.583000   \n",
       "max         997.000000        958.000000       973.00000           974.000000   \n",
       "\n",
       "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean       18.432831               64.298601  ...    315.194921   \n",
       "std        53.388748              182.029228  ...   1655.459336   \n",
       "min         0.180000                0.060000  ...      7.930000   \n",
       "25%         1.632000                5.853000  ...     13.180000   \n",
       "50%         1.813000                6.232000  ...     15.150000   \n",
       "75%         2.035000                6.899000  ...     19.850000   \n",
       "max       304.000000              898.000000  ...   9981.000000   \n",
       "\n",
       "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128         14.057726   \n",
       "std         6.146258        33.602542   569.356993         55.312800   \n",
       "min        12.020000        50.410000   185.200000          0.130000   \n",
       "25%        21.080000        84.110000   515.300000          1.223000   \n",
       "50%        25.410000        97.660000   686.500000          1.377000   \n",
       "75%        29.720000       125.400000  1084.000000          1.562000   \n",
       "max        49.540000       251.200000  4254.000000        997.000000   \n",
       "\n",
       "       compactness_worst  concavity_worst  concave_points_worst  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean           35.448107        43.673580             43.891974   \n",
       "std           122.342078       148.481678            154.494270   \n",
       "min             0.100000         0.000000              0.000000   \n",
       "25%             1.843000         1.925000              1.595000   \n",
       "50%             2.942000         3.486000              2.701000   \n",
       "75%             5.232000         6.141000              7.763000   \n",
       "max          1058.000000      1252.000000            991.000000   \n",
       "\n",
       "       symmetry_worst  fractal_dimension_worst  \n",
       "count      569.000000               569.000000  \n",
       "mean        32.661968                56.040787  \n",
       "std         89.988802               190.731370  \n",
       "min          0.210000                 0.120000  \n",
       "25%          2.527000                 6.609000  \n",
       "50%          2.871000                 7.628000  \n",
       "75%          3.313000                 8.553000  \n",
       "max        544.000000               997.000000  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave_points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave_points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave_points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.rename(columns = {'0':'Labels'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: Labels, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y['Labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividindo o dataset entre treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treinamento: (426, 30)\n",
      "Dados de treinamento: (426, 1)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dados de treinamento: {X_train.shape}\")\n",
    "print(f\"Dados de treinamento: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_model():\n",
    "    \"\"\"\n",
    "        Essa função é responsável pela construção da arquitetura da rede\n",
    "    \"\"\"\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units = 16, activation = 'relu', \n",
    "                        kernel_initializer = 'random_uniform', input_dim = 30))\n",
    "    model.add(Dense(units = 16, activation = 'relu', \n",
    "                        kernel_initializer = 'random_uniform'))\n",
    "    model.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16)                496       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                272       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn = network_model() ##30 parametros * 16 + 16 = 496 parametros para otimizar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do otimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gardin/.local/lib/python3.8/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "otimizador = tf.optimizers.Adam(lr = 0.0005, clipvalue=0.5) ##Descendente estocástico\n",
    "nn.compile(optimizer = otimizador, loss='binary_crossentropy', \n",
    "          metrics = ['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.2992 - binary_accuracy: 0.9452 - val_loss: 5.6437 - val_binary_accuracy: 0.6977\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4059 - binary_accuracy: 0.9399 - val_loss: 5.4809 - val_binary_accuracy: 0.6744\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3636 - binary_accuracy: 0.9399 - val_loss: 5.3889 - val_binary_accuracy: 0.6744\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4432 - binary_accuracy: 0.9373 - val_loss: 5.5089 - val_binary_accuracy: 0.6977\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3072 - binary_accuracy: 0.9373 - val_loss: 5.2706 - val_binary_accuracy: 0.7209\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4876 - binary_accuracy: 0.9452 - val_loss: 5.6703 - val_binary_accuracy: 0.6744\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2982 - binary_accuracy: 0.9295 - val_loss: 4.8979 - val_binary_accuracy: 0.6977\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2257 - binary_accuracy: 0.9530 - val_loss: 5.3338 - val_binary_accuracy: 0.6744\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2590 - binary_accuracy: 0.9504 - val_loss: 5.2872 - val_binary_accuracy: 0.6977\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2371 - binary_accuracy: 0.9373 - val_loss: 5.8638 - val_binary_accuracy: 0.6977\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2235 - binary_accuracy: 0.9399 - val_loss: 5.5719 - val_binary_accuracy: 0.7209\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2946 - binary_accuracy: 0.9504 - val_loss: 5.9086 - val_binary_accuracy: 0.6744\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3106 - binary_accuracy: 0.9321 - val_loss: 5.4850 - val_binary_accuracy: 0.6977\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2223 - binary_accuracy: 0.9373 - val_loss: 5.5722 - val_binary_accuracy: 0.6977\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2594 - binary_accuracy: 0.9478 - val_loss: 5.5563 - val_binary_accuracy: 0.6744\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2998 - binary_accuracy: 0.9478 - val_loss: 5.2918 - val_binary_accuracy: 0.6512\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2667 - binary_accuracy: 0.9426 - val_loss: 5.6147 - val_binary_accuracy: 0.6744\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1898 - binary_accuracy: 0.9556 - val_loss: 5.5398 - val_binary_accuracy: 0.7209\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2038 - binary_accuracy: 0.9582 - val_loss: 6.4022 - val_binary_accuracy: 0.6512\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1947 - binary_accuracy: 0.9608 - val_loss: 5.3248 - val_binary_accuracy: 0.6977\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2123 - binary_accuracy: 0.9556 - val_loss: 5.6675 - val_binary_accuracy: 0.6744\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2069 - binary_accuracy: 0.9426 - val_loss: 5.5305 - val_binary_accuracy: 0.6977\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2497 - binary_accuracy: 0.9582 - val_loss: 4.9924 - val_binary_accuracy: 0.6744\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2159 - binary_accuracy: 0.9556 - val_loss: 5.6205 - val_binary_accuracy: 0.6977\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1601 - binary_accuracy: 0.9634 - val_loss: 5.8029 - val_binary_accuracy: 0.6977\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3890 - binary_accuracy: 0.9347 - val_loss: 6.0364 - val_binary_accuracy: 0.6977\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4953 - binary_accuracy: 0.9426 - val_loss: 5.8429 - val_binary_accuracy: 0.6977\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1746 - binary_accuracy: 0.9687 - val_loss: 5.8408 - val_binary_accuracy: 0.6977\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2971 - binary_accuracy: 0.9608 - val_loss: 6.0713 - val_binary_accuracy: 0.6977\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2895 - binary_accuracy: 0.9582 - val_loss: 5.8797 - val_binary_accuracy: 0.6977\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1710 - binary_accuracy: 0.9556 - val_loss: 6.0247 - val_binary_accuracy: 0.6977\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2784 - binary_accuracy: 0.9347 - val_loss: 6.1194 - val_binary_accuracy: 0.7209\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1904 - binary_accuracy: 0.9478 - val_loss: 5.7190 - val_binary_accuracy: 0.6744\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.8977 - binary_accuracy: 0.9373 - val_loss: 5.9841 - val_binary_accuracy: 0.7209\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2203 - binary_accuracy: 0.9452 - val_loss: 5.9539 - val_binary_accuracy: 0.7209\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2522 - binary_accuracy: 0.9478 - val_loss: 6.3248 - val_binary_accuracy: 0.7209\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2771 - binary_accuracy: 0.9426 - val_loss: 6.0027 - val_binary_accuracy: 0.7209\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2878 - binary_accuracy: 0.9478 - val_loss: 6.2655 - val_binary_accuracy: 0.7442\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2911 - binary_accuracy: 0.9478 - val_loss: 5.6825 - val_binary_accuracy: 0.7442\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2057 - binary_accuracy: 0.9504 - val_loss: 6.3149 - val_binary_accuracy: 0.7209\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3191 - binary_accuracy: 0.9373 - val_loss: 6.2514 - val_binary_accuracy: 0.7209\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3199 - binary_accuracy: 0.9399 - val_loss: 6.4695 - val_binary_accuracy: 0.7209\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2481 - binary_accuracy: 0.9478 - val_loss: 6.8090 - val_binary_accuracy: 0.6977\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1556 - binary_accuracy: 0.9661 - val_loss: 6.3852 - val_binary_accuracy: 0.7209\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1576 - binary_accuracy: 0.9634 - val_loss: 6.0684 - val_binary_accuracy: 0.6977\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2093 - binary_accuracy: 0.9634 - val_loss: 6.4000 - val_binary_accuracy: 0.7209\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2802 - binary_accuracy: 0.9452 - val_loss: 6.0968 - val_binary_accuracy: 0.7209\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2908 - binary_accuracy: 0.9347 - val_loss: 5.9499 - val_binary_accuracy: 0.7442\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2097 - binary_accuracy: 0.9661 - val_loss: 6.1619 - val_binary_accuracy: 0.7209\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1825 - binary_accuracy: 0.9634 - val_loss: 6.6654 - val_binary_accuracy: 0.6977\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2658 - binary_accuracy: 0.9504 - val_loss: 6.4702 - val_binary_accuracy: 0.6744\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3050 - binary_accuracy: 0.9608 - val_loss: 6.6883 - val_binary_accuracy: 0.7209\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 1ms/step - loss: 1.0658 - binary_accuracy: 0.9347 - val_loss: 7.6496 - val_binary_accuracy: 0.6512\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3636 - binary_accuracy: 0.9478 - val_loss: 6.3822 - val_binary_accuracy: 0.6744\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2093 - binary_accuracy: 0.9399 - val_loss: 7.1421 - val_binary_accuracy: 0.7442\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4104 - binary_accuracy: 0.9478 - val_loss: 6.6154 - val_binary_accuracy: 0.6977\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2230 - binary_accuracy: 0.9478 - val_loss: 6.6158 - val_binary_accuracy: 0.6977\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2606 - binary_accuracy: 0.9478 - val_loss: 6.0586 - val_binary_accuracy: 0.6977\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4483 - binary_accuracy: 0.9452 - val_loss: 6.8958 - val_binary_accuracy: 0.6977\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2084 - binary_accuracy: 0.9530 - val_loss: 6.8438 - val_binary_accuracy: 0.6977\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2646 - binary_accuracy: 0.9661 - val_loss: 7.2446 - val_binary_accuracy: 0.7674\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 2.0505 - binary_accuracy: 0.9269 - val_loss: 6.5784 - val_binary_accuracy: 0.6977\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3497 - binary_accuracy: 0.9426 - val_loss: 6.7674 - val_binary_accuracy: 0.6977\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2373 - binary_accuracy: 0.9504 - val_loss: 7.4134 - val_binary_accuracy: 0.6744\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1690 - binary_accuracy: 0.9556 - val_loss: 7.4696 - val_binary_accuracy: 0.7209\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1206 - binary_accuracy: 0.9713 - val_loss: 7.4510 - val_binary_accuracy: 0.7209\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1334 - binary_accuracy: 0.9634 - val_loss: 7.5970 - val_binary_accuracy: 0.6977\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1683 - binary_accuracy: 0.9530 - val_loss: 7.4462 - val_binary_accuracy: 0.6977\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1753 - binary_accuracy: 0.9687 - val_loss: 7.5888 - val_binary_accuracy: 0.6977\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1773 - binary_accuracy: 0.9556 - val_loss: 7.2741 - val_binary_accuracy: 0.6977\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 2ms/step - loss: 0.1606 - binary_accuracy: 0.9687 - val_loss: 7.4917 - val_binary_accuracy: 0.6977\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1446 - binary_accuracy: 0.9608 - val_loss: 7.7583 - val_binary_accuracy: 0.6977\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1880 - binary_accuracy: 0.9530 - val_loss: 8.4064 - val_binary_accuracy: 0.7674\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4156 - binary_accuracy: 0.9347 - val_loss: 7.4527 - val_binary_accuracy: 0.7442\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2410 - binary_accuracy: 0.9713 - val_loss: 7.8463 - val_binary_accuracy: 0.6977\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2229 - binary_accuracy: 0.9634 - val_loss: 8.1958 - val_binary_accuracy: 0.6977\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1647 - binary_accuracy: 0.9634 - val_loss: 8.1848 - val_binary_accuracy: 0.6977\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3204 - binary_accuracy: 0.9687 - val_loss: 7.9163 - val_binary_accuracy: 0.7209\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2294 - binary_accuracy: 0.9713 - val_loss: 8.0991 - val_binary_accuracy: 0.7209\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3746 - binary_accuracy: 0.9634 - val_loss: 7.5488 - val_binary_accuracy: 0.6977\n",
      "Epoch 81/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3220 - binary_accuracy: 0.9582 - val_loss: 7.9464 - val_binary_accuracy: 0.7209\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6534 - binary_accuracy: 0.9112 - val_loss: 7.9359 - val_binary_accuracy: 0.6744\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1992 - binary_accuracy: 0.9661 - val_loss: 8.0366 - val_binary_accuracy: 0.7442\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.1923 - binary_accuracy: 0.9713 - val_loss: 8.0679 - val_binary_accuracy: 0.6977\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3038 - binary_accuracy: 0.9452 - val_loss: 7.8240 - val_binary_accuracy: 0.7442\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2965 - binary_accuracy: 0.9582 - val_loss: 8.1760 - val_binary_accuracy: 0.7442\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2579 - binary_accuracy: 0.9713 - val_loss: 8.2826 - val_binary_accuracy: 0.6977\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3030 - binary_accuracy: 0.9504 - val_loss: 8.0468 - val_binary_accuracy: 0.6977\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.5003 - binary_accuracy: 0.9687 - val_loss: 8.0742 - val_binary_accuracy: 0.7442\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3817 - binary_accuracy: 0.9661 - val_loss: 8.2905 - val_binary_accuracy: 0.6744\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.5202 - binary_accuracy: 0.9452 - val_loss: 8.8705 - val_binary_accuracy: 0.6977\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3723 - binary_accuracy: 0.9426 - val_loss: 8.0518 - val_binary_accuracy: 0.6744\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6565 - binary_accuracy: 0.9504 - val_loss: 7.4676 - val_binary_accuracy: 0.6977\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.4185 - binary_accuracy: 0.9556 - val_loss: 7.5207 - val_binary_accuracy: 0.7674\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6357 - binary_accuracy: 0.9243 - val_loss: 7.9048 - val_binary_accuracy: 0.6744\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.6890 - binary_accuracy: 0.9243 - val_loss: 8.2168 - val_binary_accuracy: 0.7674\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2678 - binary_accuracy: 0.9426 - val_loss: 8.3969 - val_binary_accuracy: 0.7209\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2697 - binary_accuracy: 0.9399 - val_loss: 8.6873 - val_binary_accuracy: 0.7209\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.2711 - binary_accuracy: 0.9504 - val_loss: 8.3975 - val_binary_accuracy: 0.6977\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 1ms/step - loss: 0.3672 - binary_accuracy: 0.9426 - val_loss: 7.9853 - val_binary_accuracy: 0.7209\n"
     ]
    }
   ],
   "source": [
    "history = nn.fit(X_train, y_train, batch_size = 10, validation_split = 0.1, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualização das perdas ao longo do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando os pesos da rede\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.43832594],\n",
       "        [ 0.09234864],\n",
       "        [ 0.2022974 ],\n",
       "        [-0.97448796],\n",
       "        [ 0.41025248],\n",
       "        [-0.32556862],\n",
       "        [ 0.007512  ],\n",
       "        [-0.34849378],\n",
       "        [-0.25565478],\n",
       "        [-0.34281176],\n",
       "        [-0.03223756],\n",
       "        [-0.7761257 ],\n",
       "        [-0.5910982 ],\n",
       "        [-1.0047836 ],\n",
       "        [-0.05000158],\n",
       "        [ 0.11352718]], dtype=float32),\n",
       " array([-0.06707409], dtype=float32)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pesos_0 = nn.layers[2].get_weights()\n",
    "pesos_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fase teste: verificar a acurácia da rede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia:  0.8111888111888111\n"
     ]
    }
   ],
   "source": [
    "y_pred= nn.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "target_names = ['0', '1']\n",
    "\n",
    "cmn = cm.astype('float' / cm.sum(axis=1)[:, np.newaxis])\n",
    "fig2, ax2 = plt.subplots(figsize=(11,7))\n",
    "fig2 = sns.heatmap(cmn, annot=True, fnt='.2%', xticklabels=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
